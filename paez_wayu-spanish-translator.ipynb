{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-03T22:51:58.017014Z","iopub.status.busy":"2023-12-03T22:51:58.016710Z","iopub.status.idle":"2023-12-03T22:52:11.781531Z","shell.execute_reply":"2023-12-03T22:52:11.780527Z","shell.execute_reply.started":"2023-12-03T22:51:58.016988Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n","Collecting evaluate\n","  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n","  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n","Collecting sacrebleu\n","  Obtaining dependency information for sacrebleu from https://files.pythonhosted.org/packages/0a/a6/2ac47e71e526bbcd97ea08f20d9ef7d3852e2594ec7b2d55f5d2bbfd7aae/sacrebleu-2.3.3-py3-none-any.whl.metadata\n","  Downloading sacrebleu-2.3.3-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.1.99)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.3)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.10.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n","Collecting portalocker (from sacrebleu)\n","  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n","  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n","Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.3)\n","Requirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers) (2.0.0)\n","Requirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.1)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers) (5.9.3)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers) (1.3.0)\n","Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sacrebleu-2.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Installing collected packages: portalocker, sacrebleu, evaluate\n","Successfully installed evaluate-0.4.1 portalocker-2.8.2 sacrebleu-2.3.3\n"]}],"source":["!pip install transformers datasets evaluate sacrebleu transformers[torch] sentencepiece"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:11.783886Z","iopub.status.busy":"2023-12-03T22:52:11.783542Z","iopub.status.idle":"2023-12-03T22:52:24.136099Z","shell.execute_reply":"2023-12-03T22:52:24.135326Z","shell.execute_reply.started":"2023-12-03T22:52:11.783854Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["from datasets import load_dataset\n","from transformers import MarianMTModel, MarianTokenizer, MarianConfig, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer,  PreTrainedTokenizerFast, AutoTokenizer\n","#from tokenizers import decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer\n","import torch\n","import evaluate\n","import numpy as np\n","import json"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:24.145714Z","iopub.status.busy":"2023-12-03T22:52:24.145402Z","iopub.status.idle":"2023-12-03T22:52:24.163638Z","shell.execute_reply":"2023-12-03T22:52:24.162760Z","shell.execute_reply.started":"2023-12-03T22:52:24.145690Z"},"trusted":true},"outputs":[],"source":["device = \"cuda:0\""]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:48.688352Z","iopub.status.busy":"2023-12-03T22:52:48.688086Z","iopub.status.idle":"2023-12-03T22:52:48.803879Z","shell.execute_reply":"2023-12-03T22:52:48.802964Z","shell.execute_reply.started":"2023-12-03T22:52:48.688328Z"},"trusted":true},"outputs":[],"source":["HEADS = 4\n","ENCODER_LAYERS = 6\n","DECODER_LAYERS = 6\n","HIDDEN_LAYERS = 6\n","VOCAB_SIZE = 15000\n","EPOCHS = 32\n","BATCH_SIZE = 64\n","INIT_LR = 1e-4\n","BASE_MODEL = \"Helsinki-NLP/opus-mt-es-fi\"\n","TRANSFER_LEARNING = True # Keep all other values consistent with the configurations of the model\n","USE_DICT = True\n","SOURCE_LANG = 'pbb'\n","TARGET_LANG = 'spa'"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:24.165057Z","iopub.status.busy":"2023-12-03T22:52:24.164786Z","iopub.status.idle":"2023-12-03T22:52:26.979262Z","shell.execute_reply":"2023-12-03T22:52:26.978404Z","shell.execute_reply.started":"2023-12-03T22:52:24.165035Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset parquet/Gaxys--nasa_spa to /root/.cache/huggingface/datasets/parquet/Gaxys--nasa_spa-57b1f0496f1d27f0/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2be3adc8ae54257a7cb9e54af7f4a9b","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8390e3325d2482b8f85dcaeff9f854f","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/1.32M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90155ac48d3a4b3db1576735fb65168a","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/Gaxys--nasa_spa-57b1f0496f1d27f0/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f18ea47e8892426a9d4f51d58a194fa8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["books = load_dataset(\"Gaxys/nasa_spa\")\n","\n","books = books[\"train\"].train_test_split(test_size=0.2)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:26.980724Z","iopub.status.busy":"2023-12-03T22:52:26.980367Z","iopub.status.idle":"2023-12-03T22:52:29.329837Z","shell.execute_reply":"2023-12-03T22:52:29.328875Z","shell.execute_reply.started":"2023-12-03T22:52:26.980697Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset parquet/Gaxys--nasa_spa_dict to /root/.cache/huggingface/datasets/parquet/Gaxys--nasa_spa_dict-551352ed875a0412/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8d1355fd86f46539c7039c31216f6ad","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95bc534279274913987a316cab17c392","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/102k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7ba3c4ec7bc4beebfc8224e8ce07ecb","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/Gaxys--nasa_spa_dict-551352ed875a0412/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3c6ec5cf73d450a8e775d8901ccb005","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["if USE_DICT:\n","    dictionary = load_dataset(\"Gaxys/nasa_spa_dict\")\n","    dictionary = dictionary[\"train\"].train_test_split(test_size=0.2)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:29.331561Z","iopub.status.busy":"2023-12-03T22:52:29.331274Z","iopub.status.idle":"2023-12-03T22:52:30.837207Z","shell.execute_reply":"2023-12-03T22:52:30.836161Z","shell.execute_reply.started":"2023-12-03T22:52:29.331530Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a7817e1ebbb4b228c434c5147b1170b","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16514a56ed374e57a06fd22b17b24f75","version_major":2,"version_minor":0},"text/plain":["Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f44aad695bb441c85d44958b7c6827f","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["checkpoint = \"t5-small\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint, model_max_length=128)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:30.839108Z","iopub.status.busy":"2023-12-03T22:52:30.838799Z","iopub.status.idle":"2023-12-03T22:52:31.774349Z","shell.execute_reply":"2023-12-03T22:52:31.773273Z","shell.execute_reply.started":"2023-12-03T22:52:30.839066Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n"]}],"source":["tokenizer = tokenizer.train_new_from_iterator(books['train'], VOCAB_SIZE)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:31.776019Z","iopub.status.busy":"2023-12-03T22:52:31.775653Z","iopub.status.idle":"2023-12-03T22:52:31.785422Z","shell.execute_reply":"2023-12-03T22:52:31.784266Z","shell.execute_reply.started":"2023-12-03T22:52:31.775992Z"},"trusted":true},"outputs":[],"source":["pre_trained_config = {\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"swish\",\n","  \"add_bias_logits\": False,\n","  \"add_final_layer_norm\": False,\n","  \"architectures\": [\n","    \"MarianMTModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bad_words_ids\": [\n","    [\n","      VOCAB_SIZE - 1\n","    ]\n","  ],\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 512,\n","  \"decoder_attention_heads\": 8 if TRANSFER_LEARNING else HEADS,\n","  \"decoder_ffn_dim\": 2048,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6 if TRANSFER_LEARNING else DECODER_LAYERS,\n","  \"decoder_start_token_id\": VOCAB_SIZE - 1,\n","  \"decoder_vocab_size\": VOCAB_SIZE,\n","  \"dropout\": 0.1,\n","  \"encoder_attention_heads\": 8 if TRANSFER_LEARNING else HEADS,\n","  \"encoder_ffn_dim\": 2048,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 6 if TRANSFER_LEARNING else ENCODER_LAYERS,\n","  \"eos_token_id\": 0,\n","  \"forced_eos_token_id\": 0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": True,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"max_length\": 512,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"marian\",\n","  \"normalize_before\": False,\n","  \"normalize_embedding\": False,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 6 if TRANSFER_LEARNING else HIDDEN_LAYERS,\n","  \"pad_token_id\": VOCAB_SIZE - 1,\n","  \"scale_embedding\": True,\n","  \"share_encoder_decoder_embeddings\": True,\n","  \"static_position_embeddings\": True,\n","  \"transformers_version\": \"4.35.2\",\n","  \"use_cache\": True,\n","  \"vocab_size\": VOCAB_SIZE\n","}"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:31.789913Z","iopub.status.busy":"2023-12-03T22:52:31.789142Z","iopub.status.idle":"2023-12-03T22:52:31.798408Z","shell.execute_reply":"2023-12-03T22:52:31.797577Z","shell.execute_reply.started":"2023-12-03T22:52:31.789881Z"},"trusted":true},"outputs":[],"source":["configuration = MarianConfig(**pre_trained_config)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:31.800626Z","iopub.status.busy":"2023-12-03T22:52:31.799887Z","iopub.status.idle":"2023-12-03T22:52:34.356373Z","shell.execute_reply":"2023-12-03T22:52:34.355322Z","shell.execute_reply.started":"2023-12-03T22:52:31.800573Z"},"trusted":true},"outputs":[],"source":["model = MarianMTModel(configuration)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:34.357791Z","iopub.status.busy":"2023-12-03T22:52:34.357477Z","iopub.status.idle":"2023-12-03T22:52:48.655649Z","shell.execute_reply":"2023-12-03T22:52:48.654772Z","shell.execute_reply.started":"2023-12-03T22:52:34.357766Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e787760b14224a18bd2ef772ce29b387","version_major":2,"version_minor":0},"text/plain":["Downloading config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce97103484334bf9b5b43d84eca76a6c","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/309M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8e9102b47e043acbc44de7d81e55c51","version_major":2,"version_minor":0},"text/plain":["Downloading generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tuned_model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-es-fi\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:52:48.657107Z","iopub.status.busy":"2023-12-03T22:52:48.656825Z","iopub.status.idle":"2023-12-03T22:52:48.686248Z","shell.execute_reply":"2023-12-03T22:52:48.685436Z","shell.execute_reply.started":"2023-12-03T22:52:48.657081Z"},"trusted":true},"outputs":[],"source":["parts = list(dict(model.named_parameters()).keys())\n","parts.remove('model.shared.weight')\n","\n","def transfer (tuned, to_tune, parts):\n","    \"\"\"\n","    Function to copy the weights of the pre-trained model into the new model.\n","\n","    variables:\n","    - tuned: A transformer model that is already trained on a language pair\n","    - to_tune: A transformer model that will receive the weights of the tuned model\n","    - parts: A list of names of the layers for which the weights will be copied\n","    \"\"\"\n","    target = dict(to_tune.named_parameters())\n","    source = dict(tuned.named_parameters())\n","\n","    for part in parts:\n","        target[part].data.copy_(source[part].data)\n","\n","if TRANSFER_LEARNING:\n","    transfer(tuned_model, model, parts)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:53:57.773801Z","iopub.status.busy":"2023-12-03T22:53:57.773222Z","iopub.status.idle":"2023-12-03T22:53:57.781543Z","shell.execute_reply":"2023-12-03T22:53:57.780341Z","shell.execute_reply.started":"2023-12-03T22:53:57.773760Z"},"trusted":true},"outputs":[],"source":["source_lang = SOURCE_LANG\n","target_lang = TARGET_LANG\n","\n","\n","def preprocess_function(examples):\n","    \"\"\"\n","    Function to tokenize the translations of the dataset to prepare them for the model.\n","\n","    variables:\n","    - examples: A Hugging Face dataset\n","\n","    returns:\n","    - model_inputs: The transformed inputs for the transformer model\n","    \"\"\"\n","    inputs = [example[source_lang] for example in examples[\"translation\"]]\n","    targets = [example[target_lang] for example in examples[\"translation\"]]\n","    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n","    return model_inputs"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:53:58.570827Z","iopub.status.busy":"2023-12-03T22:53:58.570462Z","iopub.status.idle":"2023-12-03T22:53:58.850667Z","shell.execute_reply":"2023-12-03T22:53:58.849762Z","shell.execute_reply.started":"2023-12-03T22:53:58.570800Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47f6ecea4a45482aa6c0cf9a0a9512fb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5192c342d59d4a65baaef9eefc5ac94d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["if USE_DICT:\n","    tokenized_dict = dictionary.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:54:03.710759Z","iopub.status.busy":"2023-12-03T22:54:03.709868Z","iopub.status.idle":"2023-12-03T22:54:05.510288Z","shell.execute_reply":"2023-12-03T22:54:05.509362Z","shell.execute_reply.started":"2023-12-03T22:54:03.710710Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d375b80cc21243c381da472dbe0b50ee","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/7 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81b6940ee766457abc8200692ef282c9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_books = books.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:54:05.514420Z","iopub.status.busy":"2023-12-03T22:54:05.514126Z","iopub.status.idle":"2023-12-03T22:54:05.518665Z","shell.execute_reply":"2023-12-03T22:54:05.517625Z","shell.execute_reply.started":"2023-12-03T22:54:05.514395Z"},"trusted":true},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:54:05.521381Z","iopub.status.busy":"2023-12-03T22:54:05.519651Z","iopub.status.idle":"2023-12-03T22:54:06.598220Z","shell.execute_reply":"2023-12-03T22:54:06.597424Z","shell.execute_reply.started":"2023-12-03T22:54:05.521355Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b198b2b2b6b42d891e4c6a2e92be130","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["metric = evaluate.load(\"sacrebleu\")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:54:09.339839Z","iopub.status.busy":"2023-12-03T22:54:09.338760Z","iopub.status.idle":"2023-12-03T22:54:09.348226Z","shell.execute_reply":"2023-12-03T22:54:09.347282Z","shell.execute_reply.started":"2023-12-03T22:54:09.339803Z"},"trusted":true},"outputs":[],"source":["def postprocess_text(preds, labels):\n","    \"\"\"\n","    Function standardize the text used in the model, removing extra spaces.\n","\n","    variables:\n","    - preds: A list of strings with predictions\n","    - labels: A list of strings with labels\n","\n","    returns:\n","    - labels, preds\n","    \"\"\"\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","\n","    return preds, labels\n","\n","\n","def compute_metrics(eval_preds):\n","    \"\"\"\n","    Function to compute the BLEU score for the predictions of a model.\n","\n","    variables:\n","    - eval_preds: A tuple with predictions and labels iterables\n","\n","    returns:\n","    - BLEU score\n","    \"\"\"\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","    result = {\"bleu\": result[\"score\"]}\n","\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","    result = {k: round(v, 4) for k, v in result.items()}\n","    return result"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:54:32.663242Z","iopub.status.busy":"2023-12-03T22:54:32.662858Z","iopub.status.idle":"2023-12-03T22:54:38.021816Z","shell.execute_reply":"2023-12-03T22:54:38.020852Z","shell.execute_reply.started":"2023-12-03T22:54:32.663211Z"},"trusted":true},"outputs":[],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"transfer_with_dict_nasa_15k_1e-4\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=INIT_LR,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=EPOCHS,\n","    predict_with_generate=True,\n","    #fp16=True,\n","    push_to_hub=False,\n","    load_best_model_at_end=True,\n","    save_strategy=\"epoch\"\n",")\n","\n","#fast_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dict[\"train\"],\n","    eval_dataset=tokenized_dict[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    #compute_metrics=compute_metrics,\n",")\n","\n","#trainer.train()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:54:46.047342Z","iopub.status.busy":"2023-12-03T22:54:46.046501Z","iopub.status.idle":"2023-12-03T23:28:20.530975Z","shell.execute_reply":"2023-12-03T23:28:20.530013Z","shell.execute_reply.started":"2023-12-03T22:54:46.047310Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231203_225539-11nszt7h</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/jlopez_nlp/huggingface/runs/11nszt7h' target=\"_blank\">copper-water-11</a></strong> to <a href='https://wandb.ai/jlopez_nlp/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/jlopez_nlp/huggingface' target=\"_blank\">https://wandb.ai/jlopez_nlp/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/jlopez_nlp/huggingface/runs/11nszt7h' target=\"_blank\">https://wandb.ai/jlopez_nlp/huggingface/runs/11nszt7h</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3328' max='3328' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3328/3328 32:07, Epoch 32/32]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>2.084489</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>1.618965</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>1.487017</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>1.405701</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.843900</td>\n","      <td>1.339887</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.843900</td>\n","      <td>1.300080</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.843900</td>\n","      <td>1.274181</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.843900</td>\n","      <td>1.244222</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.843900</td>\n","      <td>1.228137</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.303400</td>\n","      <td>1.207933</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.303400</td>\n","      <td>1.193093</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.303400</td>\n","      <td>1.176748</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>1.303400</td>\n","      <td>1.166650</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.303400</td>\n","      <td>1.160084</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>1.188100</td>\n","      <td>1.145935</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>1.188100</td>\n","      <td>1.140902</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.188100</td>\n","      <td>1.133805</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>1.188100</td>\n","      <td>1.127501</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.188100</td>\n","      <td>1.120002</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.114500</td>\n","      <td>1.121694</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>1.114500</td>\n","      <td>1.115084</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>1.114500</td>\n","      <td>1.109390</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>1.114500</td>\n","      <td>1.105042</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>1.114500</td>\n","      <td>1.099879</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>1.055600</td>\n","      <td>1.096076</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>1.055600</td>\n","      <td>1.101489</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>1.055600</td>\n","      <td>1.095186</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>1.055600</td>\n","      <td>1.095812</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>1.010200</td>\n","      <td>1.095436</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.010200</td>\n","      <td>1.095910</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>1.010200</td>\n","      <td>1.093537</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>1.010200</td>\n","      <td>1.094510</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.encoder.embed_positions.weight', 'model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'lm_head.weight'].\n"]},{"data":{"text/plain":["TrainOutput(global_step=3328, training_loss=1.2263239713815541, metrics={'train_runtime': 2014.1119, 'train_samples_per_second': 105.734, 'train_steps_per_second': 1.652, 'total_flos': 7218995795066880.0, 'train_loss': 1.2263239713815541, 'epoch': 32.0})"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"transfer_no_dict_nasa_15k_1e-4\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=INIT_LR,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=EPOCHS,\n","    predict_with_generate=True,\n","    fp16=True,\n","    push_to_hub=False,\n","    load_best_model_at_end=True,\n","    save_strategy=\"epoch\"\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_books[\"train\"],\n","    eval_dataset=tokenized_books[\"test\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator\n","    #compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T23:43:49.520488Z","iopub.status.busy":"2023-12-03T23:43:49.520115Z","iopub.status.idle":"2023-12-03T23:59:04.595355Z","shell.execute_reply":"2023-12-03T23:59:04.594462Z","shell.execute_reply.started":"2023-12-03T23:43:49.520454Z"},"trusted":true},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["eval_preds = trainer.predict(tokenized_books['test'])"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T23:59:04.597870Z","iopub.status.busy":"2023-12-03T23:59:04.597485Z","iopub.status.idle":"2023-12-03T23:59:05.389198Z","shell.execute_reply":"2023-12-03T23:59:05.388166Z","shell.execute_reply.started":"2023-12-03T23:59:04.597837Z"},"trusted":true},"outputs":[],"source":["result = compute_metrics((eval_preds.predictions, eval_preds.label_ids))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T23:59:05.393961Z","iopub.status.busy":"2023-12-03T23:59:05.392368Z","iopub.status.idle":"2023-12-03T23:59:05.400504Z","shell.execute_reply":"2023-12-03T23:59:05.399416Z","shell.execute_reply.started":"2023-12-03T23:59:05.393925Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'bleu': 1.3122, 'gen_len': 511.0}"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["result"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["with open(\"non_transfer_4_head_6_layer_with_dict_nasa_15k_1e-4.json\", 'w') as f:\n","    json.dump(trainer.state.log_history, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(\"non_transfer_4_head_6_layer_with_dict_nasa_15k_1e-4_result.json\", 'w') as f:\n","    json.dump(result, f)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
